{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_text(data):\n",
    "    #data=str(raw_data).encode('ascii', 'ignore')\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", data)\n",
    "    #print letters_only\n",
    "    lower_case = letters_only.lower()\n",
    "    words = lower_case.split()\n",
    "    cachedStopWords=stopwords.words(\"english\")\n",
    "    stop_word = [w for w in words if not w in cachedStopWords]\n",
    "    #print stop_word\n",
    "    exclude = set(string.punctuation)\n",
    "    text = [ch for ch in stop_word if ch not in exclude]\n",
    "    #print text\n",
    "    #stemmer=PorterStemmer()\n",
    "    #stemmed_text=(stemmer.stem(text))\n",
    "    #a = WordNetLemmatizer()\n",
    "    #lemmatized_text=a.lemmatize(stemmed_text)\n",
    "    processed_text = (\" \".join(text))\n",
    "    processed_text = ' '.join(word for word in processed_text.split() if 15>len(word)>3)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mega document for alt.atheism \n",
      "\n",
      "Creating mega document for comp.graphics \n",
      "\n",
      "Creating mega document for comp.os.ms-windows.misc \n",
      "\n",
      "Creating mega document for comp.sys.ibm.pc.hardware \n",
      "\n",
      "Creating mega document for comp.sys.mac.hardware \n",
      "\n",
      "Creating mega document for comp.windows.x \n",
      "\n",
      "Creating mega document for misc.forsale \n",
      "\n",
      "Creating mega document for rec.autos \n",
      "\n",
      "Creating mega document for rec.motorcycles \n",
      "\n",
      "Creating mega document for rec.sport.baseball \n",
      "\n",
      "Creating mega document for rec.sport.hockey \n",
      "\n",
      "Creating mega document for sci.crypt \n",
      "\n",
      "Creating mega document for sci.electronics \n",
      "\n",
      "Creating mega document for sci.med \n",
      "\n",
      "Creating mega document for sci.space \n",
      "\n",
      "Creating mega document for soc.religion.christian \n",
      "\n",
      "Creating mega document for talk.politics.guns \n",
      "\n",
      "Creating mega document for talk.politics.mideast \n",
      "\n",
      "Creating mega document for talk.politics.misc \n",
      "\n",
      "Creating mega document for talk.religion.misc \n",
      "\n",
      "Mega Documents created.\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "#READ FILES AND CREATE MEGA DOCUMENT FOR EACH CATEGORY\n",
    "train_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/training'\n",
    "mega_doc={}\n",
    "overall_text=''\n",
    "overall_text_list = []\n",
    "for category in os.listdir(train_path):\n",
    "    category_text=''\n",
    "    if (category!= '.DS_Store'):\n",
    "        print 'Creating mega document for', category, '\\n'\n",
    "        for filename in os.listdir(train_path + '/' + category):\n",
    "            f=open(train_path + '/' + category + '/' + filename, 'r');\n",
    "            category_text = category_text + f.read()\n",
    "            f.close()\n",
    "        overall_text = overall_text+category_text\n",
    "        overall_text=process_text(overall_text)\n",
    "        overall_text_list.append(process_text(overall_text))\n",
    "        mega_doc[category] = process_text(category_text)\n",
    "print 'Mega Documents created.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall count is 10000\n",
      "\n",
      "Category: alt.atheism ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: comp.graphics ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: comp.os.ms-windows.misc ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: comp.sys.ibm.pc.hardware ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: comp.sys.mac.hardware ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: comp.windows.x ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: misc.forsale ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: rec.autos ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: rec.motorcycles ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: rec.sport.baseball ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: rec.sport.hockey ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: sci.crypt ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: sci.electronics ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: sci.med ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: sci.space ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: soc.religion.christian ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: talk.politics.guns ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: talk.politics.mideast ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: talk.politics.misc ;\n",
      "Prior Probability: 0.05\n",
      "\n",
      "Category: talk.religion.misc ;\n",
      "Prior Probability: 0.05\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "#CALCULATE PRIOR PROBABILITIES\n",
    "train_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/training'\n",
    "#CALCULATE OVERALL COUNT\n",
    "overall_count=0\n",
    "for category in os.listdir(train_path):\n",
    "    count=0;\n",
    "    if (category!= '.DS_Store'):\n",
    "        for filename in os.listdir(train_path + '/' + category):\n",
    "            count=count+1\n",
    "        overall_count=overall_count+count\n",
    "print 'The overall count is %d'%overall_count\n",
    "#CALCULATE DOC COUNT AND PRIOR PROBABILITIES\n",
    "prior_probabilities={}\n",
    "for category in os.listdir(train_path):\n",
    "    count=0;\n",
    "    prior_prob=0\n",
    "    if (category!= '.DS_Store'):\n",
    "        print '\\nCategory:', category,';'\n",
    "        for filename in os.listdir(train_path + '/' + category):\n",
    "            count=count+1\n",
    "        prior_prob = float(count) / (overall_count)\n",
    "        print 'Prior Probability:', prior_prob\n",
    "    prior_probabilities[category]=prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Generated.\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "#VECTORIZE THE TEXT AND EXTRACT VOCABULARY\n",
    "data_vectorizer = CountVectorizer(input=overall_text_list, decode_error= 'ignore', analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = 'english', max_features = 100000)\n",
    "train_data_features = data_vectorizer.fit_transform(overall_text_list)\n",
    "train_data_features_array = train_data_features.toarray()\n",
    "#print train_data_features\n",
    "#for i in range(len(train_data_features_array[0])):\n",
    "#    for j in range(len(train_data_features_array[i])):\n",
    "#        print train_data_features_array[i][j]\n",
    "#print train_data_features_array\n",
    "vocab = data_vectorizer.get_feature_names()\n",
    "print 'Vocabulary Generated.'\n",
    "#dist=train_data_features_array.sum(axis=0)\n",
    "#feature_names = np.asarray(vocab)\n",
    "#for name in feature_names:\n",
    "#    print name\n",
    "#print dist\n",
    "#for tag, count in zip(vocab, dist):\n",
    "#    print tag\n",
    "#    print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "#CALCULATE LIKELIHOOD AND CORRESPONDING DICTIONARY\n",
    "train_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/training'\n",
    "likelihood_dict_outer={}\n",
    "for category in os.listdir(train_path):\n",
    "    print category\n",
    "    likelihood_dict_inner={}\n",
    "    word_count=0\n",
    "    for word in vocab:\n",
    "        if (word in mega_doc[category].split()):\n",
    "            #mega_doc[category].split()\n",
    "            word_count = mega_doc[category].count(word)\n",
    "        else:\n",
    "            word_count=0\n",
    "        likelihood = float(word_count+1)/((len(mega_doc[category].split()))+len(vocab))\n",
    "        likelihood_dict_inner[word]=likelihood\n",
    "    likelihood_dict_outer[category]=likelihood_dict_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TESTING\n",
    "#CALCULATE POSTERIOR PROBABILITY\n",
    "test_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/testing'\n",
    "predict_dict={}\n",
    "for test_filename in os.listdir(test_path):\n",
    "    if test_filename != \".DS_Store\":\n",
    "        f=open(test_path + '/' + test_filename,'r')\n",
    "        d = process_text(f.read()).split()\n",
    "        posterior_probabilities={}\n",
    "        overall_categories=['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "        for category in overall_categories:\n",
    "            posterior_likelihood=1\n",
    "            for word in d:\n",
    "                if word in vocab:\n",
    "                    posterior_likelihood=posterior_likelihood*likelihood_dict_outer[category][word]\n",
    "            posterior_probabilities[category]=((posterior_likelihood)*(prior_probabilities[category]))\n",
    "        predict_dict[test_filename]=max(posterior_probabilities.iteritems(), key=operator.itemgetter(1))[0]\n",
    "        f.close()\n",
    "#print 'Predicted Classes:', predict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Classes: {'8514': 'comp.os.ms-windows.misc', '9136': 'comp.os.ms-windows.misc'}\n",
      "\n",
      "Number of correctly predicted documents=5297\n",
      "Total number of documents=9118\n",
      "Mean Detection Accuracy=58.093880 %\n"
     ]
    }
   ],
   "source": [
    "#EVALUATION\n",
    "test_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/testing/'\n",
    "test_label_path='/Users/VA/Documents/MS/Acads/Fall15/ML/20_newsgroups_final/testing_labels/'\n",
    "overall_categories=['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "filename_labels={}\n",
    "for category in overall_categories:\n",
    "    for filename in os.listdir(test_path):\n",
    "        if (os.path.isfile(test_label_path+str(category)+ '/' + str(filename)))==True:\n",
    "            filename_labels[filename]=category\n",
    "print 'Original Classes:', filename_labels\n",
    "count=0;\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    if (filename != '.DS_Store'):\n",
    "        if filename_labels[filename]==predict_dict[filename]:\n",
    "            count=count+1\n",
    "print '\\nNumber of correctly predicted documents=%d'%count\n",
    "print 'Total number of documents=%d'%len(predict_dict)\n",
    "accuracy = float(count*100)/len(predict_dict)\n",
    "print 'Mean Detection Accuracy=%f'%accuracy,'%'        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
